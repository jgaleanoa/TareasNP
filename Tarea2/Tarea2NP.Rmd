---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.pos = "center")
library(kableExtra)
library(knitr)
library(tidyverse)
library(gtools)
```

\input{PortadaNP}
\thispagestyle{empty}
\tableofcontents

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

\section{Ejercicio 4.1.6)}

Use la prueba exacta de Fisher como un test para correlación positiva, como se 
explicó en el ejercicio 5, para los datos en el ejemplo 3.5.4. Allí se administró 
la reacción de un paciente al fármaco 1 ($X$) y la reacción del mismo paciente al
fármaco 2 ($Y$) para 10 pacientes. (0.7, 1.9), (-1.6, 0.8), (-0.2, 1.1), 
(-1.2, 0.1), (-0.1, -0.1), (3.4, 4.4), (3.7, 5.5), (0.8, 1.6), (0.0, 4.6), 
(2.0, 3.4). Compare el valor-p usando la prueba exacta de Fisher con 0.0312, 
el valor-p obtenido en la sección 3.5 usando los test de Cox y Stuart para 
tendencia como un test de correlación.

\begin{center}
\textbf{Solución}
\end{center}

Se definen y organizan las variables aleatorias X e Y en la siguiente tabla:

\begin{itemize}
\item $X:$ Reacción del paciente al fármaco 1
\item $Y:$ Reacción del mismo paciente al fármaco 2
\end{itemize}

```{r DatosEJ1}
x <- c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0, 2.0)
y <- c(1.9, 0.8, 1.1, 0.1, -0.1, 4.4, 5.5, 1.6, 4.6, 3.4)
datos1 <- data.frame(X = x, Y = y) %>% t()
kable(datos1, longtable = T, booktabs = T, 
      caption = "Reacción del paciente al fármaco")
```

Como se quiere usar el test exacto de Fisher para probar correlación entre las variables $X$ e $Y$, se realiza un diagrama de dispersión el cual se divide en cuatro cuadrantes al dividir el rango de $X$ en su mediana y similarmente con $Y$.

```{r scatterplot1}
median_x <- median(x); median_y <- median(y)
ggplot(mapping = aes(x = x, y = y)) + 
  geom_point() +
  geom_segment(aes(x = median_x, xend = median_x,
                   y = 0, yend = 6)) +
  geom_segment(aes(x = -2, xend = 4,
                   y = median_y, yend = median_y)) +
  theme_bw()
```

Del diagrama de dispersión se construye la siguiente tabla

```{r tabla_mediana1}
#Para imprimir
tabla_mediana1 <- data.frame(Col1 = c(1, 4, 5),
                             Col2 = c(4, 1, 5),
                             Total = c(5, 5, 10))
rownames(tabla_mediana1) <- c("Fila 1", "Fila 2", "Total")
kable(tabla_mediana1, longtable = T, booktabs = T,
      caption = "Tabla para test de correlación positiva", 
      col.names = c("Columna 1", "Columna 2", "Total"))

#Para el test de fisher
tabla1 <- matrix(c(1, 4,
                   4, 1), ncol = 2, byrow = T)
```

Como se quiere probar correlación positiva se plantea el siguiente juego de hipótesis

$$
\begin{cases}
H_0: P_1 \geq P_2 \\
H_1: P_1 < P2
\end{cases}
$$

Se usa el estadístico de prueba 

* $T_2: \text{Número de observaciones en la celda de la fila 1, columna 1}$

Donde bajo $H_0$, $P(T_2 = t_2) = \frac{\binom{r}{t_2} \binom{N - r}{C - t_2}}{\binom{N}{C}} \hspace{.2in} x=0, 1, 2, \cdots ,\text{min}\lbrace r, C\rbrace$.

```{r pvalue_a_mano}
N <- 10; C <- 5; r <- 5
pvalor <- 0
for (i in 0:1) {
  pvalor <-  pvalor + (choose(r, i) * choose(N - r, C - i))/choose(N, C)
}
```


En esta situación se tiene que $r = 5,\ C = 5,\ N = 10$ y el estadístico de 
prueba es $T_{2\text{obs}} = 1$. Dadas estas cantidades se calcula el valor-p 
como $\mathbb{P}(T_2 \leq T_{2\text{obs}}) = \mathbb{P}({T_{2\text{obs}} \leq 1}) = `r pvalor %>% round(4)`$ con lo que a un nivel de significancia de $\alpha = 0.05$ 
no se rechaza $H_0$ y se concluye que no hay correlación positiva entre $X$ e $Y$.

Comparando con el valor-p del ejemplo mencionado (3.5.4), allí se obtuvo un valor 
de 0.0312 el cual es suficiente para rechazar la hipótesis nula, sin embargo la
prueba exacta de Fisher no rechaza, esto se puede deber a que una de ellas es 
más potente que la otra y la cantidad de datos es límitada.

\section{Ejercicio 4.2.6)}

Un equipo de observadores se mueve a través de un área boscosa e informa todos 
los avistamientos, falsos y verdaderos, de equipo camuflado. Se utilizan dos 
tipos de camuflaje, liso y estampado. El informe del equipo incluye el tipo 
de camuflaje utilizado y la ubicación del equipoamiento. El equipo está siendo
monitoreado por una persona que sabe qué avistamientos son verdaderos y cuáles
son falsos. Los resultados de avistamientos verdaderos y falsos son los siguientes.

```{r camuflajes}
Estampado <- c(14, 27); Liso <- c(4, 32)
Camuflaje <- data.frame(Estampado = Estampado, Liso = Liso)
rownames(Camuflaje) <- c("Falsas detecciones", "Verdaderas detecciones")
kable(Camuflaje, longtable = T, booktabs = T, caption = "Tipos de camuflaje")
```
¿Existe una diferencia significativa en la probabilidad de que un avistamiento
informado sea incorrecto? (Tenga en cuenta que este estudio no se ocupa de 
equipos no detectados ni de avistamientos que identifiquen erróneamente el 
tipo de camuflaje) ¿Qué tipo de tabla de contingencia es esta?

\section{Ejercicio 4.4.2)} 

Cincuenta trabajadores de fabrica se reportan en la enfermería por dolor debido 
a la artritis. Veinticinco de ellos. A veinticinco de ellos se les administró 
aspirina y al resto se les dio un placebo sin su conocimiento. Una hora después 
se les preguntó si la pastilla que tomaron les ayudó a sentirse mejor. Diecisiete 
en el grupo de aspirina y doce en el grupo de placebo dijeron que sí.

**a)** Use $R_5$ para ver si existe una correlación positiva entre tomar 
aspirina y sentirse mejor.

**b)** Calcule $R_6$.

**c)** Calcule $R_7$

\section{Ejercicio 4.5.6)}

Se obtuvieron veintiséis observaciones y surgió la pregunta de si siguen una
distribución normal con media 12 y desviación estándar 3. Ninguna de las 
observaciones estuvo por debajo del cuartil inferior de esta distribución y 
12 por encima del cuartil superior. Seis estaban por debajo de la mediana y
ocho entre la mediana y el cuartil superior. ¿Parece que estas observaciones 
proceden de la distribución descrita?

```{r DatosEJ4}
datos4 <- data.frame(Probabilidad = c(0.25, 0.5, 0.75),
                     Observacion = c(0, 14, 12)) %>% t()
rownames(datos4) <- c( "Probabilidad", "Observación")
kable(datos4, longtable = T, booktabs = T, 
      caption = "Información suministrada")
```


\section{Ejercicio 4.6.3)}

En un intento de comparar el poder relativo de tres pruebas estadísticas, 
se generaron 100 conjuntos de datos artificiales utilizando una computadora.
En cada uno de los datos se utilizaron las tres pruebas estadísticas, con
$\alpha = 0.05$, y se registró la decisión de aceptar o rechazar $H_0$.
Los resultados fueron los siguientes

```{r potencia}
test1 <- c(rep("Acepta", 3), rep("Rechaza", 3), "Acepta", "Rechaza")
test2 <- c(rep("Acepta", 2), "Rechaza", "Acepta", "Rechaza", "Acepta", 
           rep("Rechaza", 2))
test3 <- c("Acepta", "Rechaza", rep("Acepta", 3), rep("Rechaza", 3))
number_sets <- c(26, 6, 12, 4, 18, 5, 7, 22)
potencia <- data.frame(Prueba1 = test1, Prueba2 = test2, Prueba3 = test3,
                       conjuntos_prueba = number_sets)
kable(potencia, longtable = T, booktabs = T, caption = "Potencia de las pruebas",
      col.names = c("Prueba 1", "Prueba 2", "Prueba 3", 
                    "Número de conjuntos de datos"))
```

¿Existe una diferencia en la potencia de las tres pruebas cuando se aplican a 
las poblaciones de las que se obtuvieron los datos simulados?






