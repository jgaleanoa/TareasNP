---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.pos = "center")
library(kableExtra)
library(knitr)
library(tidyverse)
library(gtools)
```

\input{PortadaNP}
\thispagestyle{empty}
\tableofcontents

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

\section{Ejercicio 4.1.6)}

Use la prueba exacta de Fisher como un test para correlación positiva, como se 
explicó en el ejercicio 5, para los datos en el ejemplo 3.5.4. Allí se administró 
la reacción de un paciente al fármaco 1 ($X$) y la reacción del mismo paciente al
fármaco 2 ($Y$) para 10 pacientes. (0.7, 1.9), (-1.6, 0.8), (-0.2, 1.1), 
(-1.2, 0.1), (-0.1, -0.1), (3.4, 4.4), (3.7, 5.5), (0.8, 1.6), (0.0, 4.6), 
(2.0, 3.4). Compare el valor-p usando la prueba exacta de Fisher con 0.0312, 
el valor-p obtenido en la sección 3.5 usando los test de Cox y Stuart para 
tendencia como un test de correlación.

\begin{center}
\textbf{Solución}
\end{center}

Se definen y organizan las variables aleatorias X e Y en la siguiente tabla:

\begin{itemize}
\item $X:$ Reacción del paciente al fármaco 1
\item $Y:$ Reacción del mismo paciente al fármaco 2
\end{itemize}

```{r DatosEJ1}
x <- c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0, 2.0)
y <- c(1.9, 0.8, 1.1, 0.1, -0.1, 4.4, 5.5, 1.6, 4.6, 3.4)
datos1 <- data.frame(X = x, Y = y) %>% t()
kable(datos1, longtable = T, booktabs = T, 
      caption = "Reacción del paciente al fármaco")
```

Como se quiere usar el test exacto de Fisher para probar correlación entre las variables $X$ e $Y$, se realiza un diagrama de dispersión el cual se divide en cuatro cuadrantes al dividir el rango de $X$ en su mediana y similarmente con $Y$.

```{r scatterplot1}
median_x <- median(x); median_y <- median(y)
ggplot(mapping = aes(x = x, y = y)) + 
  geom_point() +
  geom_segment(aes(x = median_x, xend = median_x,
                   y = 0, yend = 6)) +
  geom_segment(aes(x = -2, xend = 4,
                   y = median_y, yend = median_y)) +
  theme_bw()
```

Del diagrama de dispersión se construye la siguiente tabla

```{r tabla_mediana1}
#Para imprimir
tabla_mediana1 <- data.frame(Col1 = c(1, 4, 5),
                             Col2 = c(4, 1, 5),
                             Total = c(5, 5, 10))
rownames(tabla_mediana1) <- c("Fila 1", "Fila 2", "Total")
kable(tabla_mediana1, longtable = T, booktabs = T,
      caption = "Tabla para test de correlación positiva", 
      col.names = c("Columna 1", "Columna 2", "Total"))

#Para el test de fisher
tabla1 <- matrix(c(1, 4,
                   4, 1), ncol = 2, byrow = T)
```

Como se quiere probar correlación positiva se plantea el siguiente juego de hipótesis

$$
\begin{cases}
H_0: P_1 \geq P_2 \\
H_1: P_1 < P2
\end{cases}
$$

Se usa el estadístico de prueba 

* $T_2: \text{Número de observaciones en la celda de la fila 1, columna 1}$

Donde bajo $H_0$, $P(T_2 = t_2) = \frac{\binom{r}{t_2} \binom{N - r}{C - t_2}}{\binom{N}{C}} \hspace{.2in} x=0, 1, 2, \cdots ,\text{min}\lbrace r, C\rbrace$.

```{r pvalue_a_mano}
N <- 10; C <- 5; r <- 5
pvalor <- 0
for (i in 0:1) {
  pvalor <-  pvalor + (choose(r, i) * choose(N - r, C - i))/choose(N, C)
}
```


En esta situación se tiene que $r = 5,\ C = 5,\ N = 10$ y el estadístico de 
prueba es $T_{2\text{obs}} = 1$. Dadas estas cantidades se calcula el valor-p 
como $\mathbb{P}(T_2 \leq T_{2\text{obs}}) = \mathbb{P}({T_{2\text{obs}} \leq 1}) = `r pvalor %>% round(4)`$ con lo que a un nivel de significancia de $\alpha = 0.05$ 
no se rechaza $H_0$ y se concluye que no hay correlación positiva entre $X$ e $Y$.

Comparando con el valor-p del ejemplo mencionado (3.5.4), allí se obtuvo un valor 
de 0.0312 el cual es suficiente para rechazar la hipótesis nula, sin embargo la
prueba exacta de Fisher no rechaza, esto se puede deber a que una de ellas es 
más potente que la otra y la cantidad de datos es límitada.

\section{Ejercicio 4.2.6)}

Un equipo de observadores se mueve a través de un área boscosa e informa todos 
los avistamientos, falsos y verdaderos, de equipo camuflado. Se utilizan dos 
tipos de camuflaje, liso y estampado. El informe del equipo incluye el tipo 
de camuflaje utilizado y la ubicación del equipamiento. El equipo está siendo
monitoreado por una persona que sabe qué avistamientos son verdaderos y cuáles
son falsos. Los resultados de avistamientos verdaderos y falsos son los siguientes.

```{r camuflajes}
Estampado <- c(14, 27); Liso <- c(4, 32)
Camuflaje <- data.frame(Estampado = Estampado, Liso = Liso)
rownames(Camuflaje) <- c("Detecciones falsas", "Detecciones verdaderas")
kable(Camuflaje, longtable = T, booktabs = T, caption = "Tipos de camuflaje")
```

¿Existe una diferencia significativa en la probabilidad de que un avistamiento
informado sea incorrecto? (Tenga en cuenta que este estudio no se ocupa de 
equipos no detectados ni de avistamientos que identifiquen erróneamente el 
tipo de camuflaje) ¿Qué tipo de tabla de contingencia es esta?

\begin{center}
\textbf{Solución}
\end{center}

Dado que la persona que está monitoreando la operación conoce el número exacto 
de observaciones verdaderas y falsas, los totales marginales para los tipos de
camuflaje son fijos porque si conoce cuales son falsos y cuales son verdaderos, 
debe saber el número total de equipos de camuflaje, por lo que se reescribe la 
tabla de la siguiente manera:

```{r tabla2}
camuflaje2 <- data.frame(Falsas = c(14, 4, 18),
                         Verdaderas = c(27, 32, 59),
                         Total = c(41, 36, 77))
rownames(camuflaje2) <- c("Estampado", "Liso", "Total")
kable(camuflaje2, longtable = T, booktabs = T, 
      caption = "Reescritura de la información", 
      col.names = c("Detecciones falsas", "Detecciones verdaderas",
                    "Total"))
```

Se plantea el siguiente conjunto de hipótesis 

$$
\begin{cases}
H_0: P_1 = P_2 \\
H_1: P_1 \neq P_2
\end{cases}
$$
Para probar si existe diferencia entre la probabilidad de que un avistamiento sea
informado incorrecto se usa la prueba $\chi^2$ para diferencias de probabilidades.

$$
\begin{aligned}
T = T_1^2 &= \frac{77\left(14 \times 32 -27 \times 4\right)^2}{41 \times 36 \times 18 \times 59} = 5.6786 \\
\text{Valor-P} &= \mathbb{P}(\chi_1^2 > 5.6786) = 0.0172
\end{aligned}
$$
Como el Valo-p < 0.05 se rechaza $H_0$ y se concluye que existe diferencia en la probabilidad de que un avistamiento sea detectado como incorrecto. 

\section{Ejercicio 4.4.2)} 

Cincuenta trabajadores de fabrica se reportan en la enfermería por dolor debido 
a la artritis. Veinticinco de ellos. A veinticinco de ellos se les administró 
aspirina y al resto se les dio un placebo sin su conocimiento. Una hora después 
se les preguntó si la pastilla que tomaron les ayudó a sentirse mejor. Diecisiete 
en el grupo de aspirina y doce en el grupo de placebo dijeron que sí.

**a)** Use $R_5$ para ver si existe una correlación positiva entre tomar 
aspirina y sentirse mejor.

\begin{center}
\textbf{Solución}
\end{center}

$$R_5=\frac{ad-bc}{\sqrt{r_1r_2c_1c_2}}=\frac{17\cdot13-12\cdot8}{\sqrt{25\cdot25\cdot29\cdot21}}\approx0.2026$$

**b)** Calcule $R_6$.

\begin{center}
\textbf{Solución}
\end{center}

$$R_6=\frac{ad-bc}{ad+bc}=\frac{17\cdot13-12\cdot8}{17\cdot13+12\cdot8}\approx0.3943$$


**c)** Calcule $R_7$

\begin{center}
\textbf{Solución}
\end{center}

$$R_7=\frac{(a+d)-(b+c)}{a+b+c+d}=\frac{30-20}{50}=0.2$$
Por los valores $R_5,R_6$ y $R_7$ calculados se concluye que existe una correlación positiva entre tomar aspirina y sentirse mejor.

\section{Ejercicio 4.5.6)}

Se obtuvieron veintiséis observaciones y surgió la pregunta de si siguen una
distribución normal con media 12 y desviación estándar 3. Ninguna de las 
observaciones estuvo por debajo del cuartil inferior de esta distribución y 
12 por encima del cuartil superior. Seis estaban por debajo de la mediana y
ocho entre la mediana y el cuartil superior. ¿Parece que estas observaciones 
proceden de la distribución descrita?

\begin{center}
\textbf{Solución}
\end{center}

Por la información dada en el problema se construye la siguiente tabla

```{r DatosEJ4}
datos4 <- data.frame(Probabilidad = c(0.25, 0.5, 0.75),
                     Observacion = c(0, 14, 12)) %>% t()
rownames(datos4) <- c( "Probabilidad", "Observación")
kable(datos4, longtable = T, booktabs = T, 
      caption = "Información suministrada")
```

La hipotesis a probar es:

$$
\begin{cases}
H_0: \text{Las observaciones provienen de una }N(12,3) \\
H_1: \text{Las observaciones no provienen de una }N(12,3)
\end{cases}
$$
Se utiliza el test de bondad de ajuste $\chi^2$ y se calcula el respectivo estadistico de prueba acontinuación:

\begin{gather*}
E_1=N\cdotp_1=26\cdot 0.25=6.5
\\
E_2=N\cdotp_2=26\cdot 0.5=13
\\
E_3=N\cdotp_3=26\cdot 0.25=6.5
\\
\end{gather*}

Luego el estadistico $T$ calculado es:

\begin{gather*}
T=\sum_{j=1}^{3}\frac{(O_j-E_j)^2}{E_j}=\sum_{j=1}^{3}\frac{O_j)^2}{E_j}-N
\\
T=(\frac{0^2}{6.5}+\frac{14^2}{13}+\frac{12^2}{6.5})-26
\\
T_{calculado}=11.2307,T\sim \chi^2_{c-1}\approx \chi^2_2
\end{gather*}

El valor p de la prueba es:
$$p=P(\chi^2_2\geq11.2307)=0.00364$$
Como el valor p es menor para cualquier $\alpha<0.01$ se rechaza $H_0$, es decir, hay evidencia muestral suficiente para sugerir que las observaciones no provienen de una $NOR(12,3)$ .

\section{Ejercicio 4.6.3)}

En un intento de comparar el poder relativo de tres pruebas estadísticas, 
se generaron 100 conjuntos de datos artificiales utilizando una computadora.
En cada uno de los datos se utilizaron las tres pruebas estadísticas, con
$\alpha = 0.05$, y se registró la decisión de aceptar o rechazar $H_0$.
Los resultados fueron los siguientes

```{r potencia}
test1 <- c(rep("Acepta", 3), rep("Rechaza", 3), "Acepta", "Rechaza")
test2 <- c(rep("Acepta", 2), "Rechaza", "Acepta", "Rechaza", "Acepta", 
           rep("Rechaza", 2))
test3 <- c("Acepta", "Rechaza", rep("Acepta", 3), rep("Rechaza", 3))
number_sets <- c(26, 6, 12, 4, 18, 5, 7, 22)
potencia <- data.frame(Prueba1 = test1, Prueba2 = test2, Prueba3 = test3,
                       conjuntos_prueba = number_sets)
kable(potencia, longtable = T, booktabs = T, caption = "Potencia de las pruebas",
      col.names = c("Prueba 1", "Prueba 2", "Prueba 3", 
                    "Número de conjuntos de datos"))
```

¿Existe una diferencia en la potencia de las tres pruebas cuando se aplican a 
las poblaciones de las que se obtuvieron los datos simulados?

La información del problema puede ser reescrita de la siguiente manera

```{r tabla pruebas}
test_reescrita <- data.frame("Filas"=c(1,2,3,"...",56,"...",100,"Total"),
                         "Test1"=c(1,1,1," ",0," ",0,51),
                         "Test2"=c(1,1,1," ",0," ",0,41),
                         "Test3"=c(1,1,1," ",1," ",0,60),
                         "Total"=c(3,3,3," ",1," ",0,152)
                         )

kable(test_reescrita,longtable = T, booktabs = T, caption = "Información reescrita",
      col.names = c("Filas", "Test 1", "Test 2", "Test 3","Total"))
```

La anterior tabla se resume acontinuación:

\newpage

```{r tabla_pruebas}
test_resum <- data.frame("Filas"=c(1:8,"Total"),
                         "Test1"=c(26,6,12,0,0,0,7,0,51),
                         "Test2"=c(26,6,0,4,0,5,0,0,41),
                         "Test3"=c(26,0,12,4,18,0,0,0,60),
                         "Total"=c(78,12,24,8,18,5,7,0,152)
                         )

kable(test_resum,longtable = T, booktabs = T, caption = "Información resumida",
      col.names = c("Filas", "Test 1", "Test 2", "Test 3","Total"))
```

La hipotesis a probar es:

$$
\begin{cases}
H_0: \text{La potencia de las 3 pruebas es igual} \\
H_1: \text{La potencia de las 3 pruebas es diferente}
\end{cases}
$$
Se utiliza el estadistico $T=\frac{c(c-1)\sum_{j=1}^3C_j-(c-1)\cdot N^2}{c\cdot N-\sum_{i=1}^{100}R_i}$ para contrastar la hipotesis. Se tiene:

$$c=3,r=100,N=152,\sum_{j=1}^3C_j=7882,\sum_{i=1}^{100}R_i=325$$
Luego el T calculado es:


\begin{gather*}
T=\frac{(6\cdot 7882)-(2\cdot 23104)}{456-352}=\frac{1084}{104}
\\
T_{calculado}=10.42308,T\chi^2_{0.95,2}
\\
\chi^2_{0.95,2}=5.991
\end{gather*}

El $T_{calculado}$ cae en la región critica, por lo tanto se rechaza $H_0$, es decir, hay evidencia muestral suficiente para suguerir que la potencia de las 3 pruebas no es igual a un nivel de significancia de $\alpha=0.05$.

